{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c5b40d",
   "metadata": {},
   "source": [
    "# Notebook de Entrenamiento de Algoritmos para despliegue en BentoML\n",
    "Este notebook consistirá en la creación y entrenamiento de nuestros de algoritmos aplicados a nuestro dataset **ai4i2020** para predecir/clasificar fallos maquinarios. Intercalando código y explicación, trataremos con diferentes algoritmos de diferente dificultad para contrastar resultados y dejar todos preparados para ser desplegados mediante la API creada en una interfaz gráfica creada mediante **Streamlit**.\n",
    "\n",
    "Cabe objetar que intentaremos desplegar el código de la mejor forma para su futura reutilización en otras partes del proyecto, siguiendo fomrmato similar al visto en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67173918",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d58e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Algoritmos que probaremos\n",
    "from sklearn.linear_model import LogisticRegression # fallo/no fallo\n",
    "from sklearn.ensemble import RandomForestClassifier # clasificación de errores\n",
    "from sklearn import svm # Support vector machines para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646b382",
   "metadata": {},
   "source": [
    "## 1. Algoritmos de Regresión\n",
    "Mediante los algoritmos regresivos que probaremos, intentaremos realizar las mejores predicciones posibles para intentar anticiparnos al fallo de nuestras máquinas sintéticas. Ya que la variable que nos interesa (**Machine failure**) tiene un output binario de 0 (no ha habido fallo) o de 1 (ha habido fallo), nos hemos decantado por realizar una regresión logística primero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc0587",
   "metadata": {},
   "source": [
    "### 1.1 Regresión Logística\n",
    "Intentaremos predecir el output binario que indica si el proceso ha fallado o no, mediante una implementación básica de este primer algoritmo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e82e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada algoritmo haremos una función diferente; creando un modelo diferente para la model store, nombre diferente, ...\n",
    "def logistic_regression():\n",
    "    dataset = pd.read_csv(\"../../data/ai4i2020.csv\")\n",
    "\n",
    "    # Como X cogemos todas las columnas menos la variable que usaremos como 'y' y la variable de identificador\n",
    "    X, y = dataset.drop(columns=[\"UDI\", \"Machine failure\"]), dataset[\"Machine failure\"] \n",
    "\n",
    "    # Pasamos a númericas las variables categóricas\n",
    "    columnas_categoricas = X.select_dtypes(include=[\"object\"]).columns\n",
    "    X = pd.get_dummies(X, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "    # Dividimos el dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "    \n",
    "    # Inicializamos el modelo de regresión logística\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    preds = lr.predict(X_test)\n",
    "\n",
    "    # Por ahora solo tendremos como métrica de evaluación la accuracy\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    print(f\"Accuracy obtenida: {accuracy:.4f}\")\n",
    "\n",
    "    # A partir de ahora, configuraremos el modelo para que sea compatible con BentoML\n",
    "    bento_lr = bentoml.sklearn.save_model(\n",
    "        \"ai4i2020_logistic_regression\",\n",
    "        lr,\n",
    "        metadata={\n",
    "            \"fecha_entrenamiento\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"dataset\": \"ai4i2020\",\n",
    "            \"framework\": \"scikit-learn\",\n",
    "            \"algoritmo\": \"regresión logística\",\n",
    "            \"precision\": accuracy,\n",
    "            \"carta_favorita_cr\": \"Reina Arquera MOMO SHOW\"\n",
    "        },\n",
    "    )\n",
    "    print(f\"Modelo de Regresión Logística guardado en la BentoML store como: {bento_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf238440",
   "metadata": {},
   "source": [
    "Y lo ejecutamos corriendo esta simple celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc92952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unai/miniconda3/envs/coran-nlp/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/unai/miniconda3/envs/coran-nlp/lib/python3.11/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtenida: 0.9960\n",
      "Modelo de Regresión Logística guardado en la BentoML store como: Model(tag=\"ai4i2020_logistic_regression:oioz27wpjsumt7fk\")\n"
     ]
    }
   ],
   "source": [
    "logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d389554",
   "metadata": {},
   "source": [
    "## 2. Algoritmos de Clasificación\n",
    "En esta segunda sección de algoritmos, en vez de predecir el resultado del proceso maquinario, intentaremos clasificar el fallo (en el caso de que haya habido) dentro de los distintos tipos de fallas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8997bc",
   "metadata": {},
   "source": [
    "### 2.1 Random Forest\n",
    "Mediante el random forest intentaremos clasificar los errores de los procesos sintéticos en los 5 tipos de errores que existen y enlista nuestro dataset:\n",
    "- TWF: Fallo por desgaste de herramienta.\n",
    "- HDF: Fallo por una mala disipación de calor.\n",
    "- PWF: Falla por potencia fuera de rango.\n",
    "- OSF: Fallo por un sobreesfuerzo mecánico.\n",
    "- RNF: Un fallo aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ddd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest():\n",
    "    dataset = pd.read_csv(\"../../data/ai4i2020.csv\")\n",
    "\n",
    "    # Como X cogemos todas las columnas menos la variable que usaremos como 'y' y la variable de identificador\n",
    "    X, y = dataset.drop(columns=[\"UDI\", \"Machine failure\", \"TWF\", \"HDF\", \"PWF\", \"RNF\", \"OSF\"]), dataset[[\"TWF\", \"HDF\", \"PWF\", \"RNF\", \"OSF\"]]\n",
    "\n",
    "    # Pasamos a númericas las variables categóricas\n",
    "    columnas_categoricas = X.select_dtypes(include=[\"object\"]).columns\n",
    "    X = pd.get_dummies(X, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "    # Dividimos el dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "    # Inicializamos el modelo de regresión logística\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Realizamos las predicciones\n",
    "    preds = rf.predict(X_test)\n",
    "\n",
    "    # Por ahora solo tendremos como métrica de evaluación la accuracy\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    print(f\"Accuracy obtenida: {accuracy:.4f}\")\n",
    "\n",
    "    # A partir de ahora, configuraremos el modelo para que sea compatible con BentoML\n",
    "    bento_rf = bentoml.sklearn.save_model(\n",
    "        \"ai4i2020_random_forest\",\n",
    "        rf,\n",
    "        metadata={\n",
    "            \"fecha_entrenamiento\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"dataset\": \"ai4i2020\",\n",
    "            \"framework\": \"scikit-learn\",\n",
    "            \"algoritmo\": \"clasificación con random forest\",\n",
    "            \"precision\": accuracy,\n",
    "            \"carta_favorita_cr\": \"Reina Arquera MOMO SHOW\"\n",
    "        },\n",
    "    )\n",
    "    print(f\"Modelo de Clasificación con Random Forest guardado en la BentoML store como: {bento_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f81cec",
   "metadata": {},
   "source": [
    "Para ejecutar el Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7df4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtenida: 0.9710\n",
      "Modelo de Clasificación con Random Forest guardado en la BentoML store como: Model(tag=\"ai4i2020_random_forest:rzbs6agpjsumt7fk\")\n"
     ]
    }
   ],
   "source": [
    "random_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172e36a",
   "metadata": {},
   "source": [
    "### 2.2 Suppor Vector Machines (SVMs)\n",
    "Este algoritmo de clasificación más pesado buscará separar las observaciones donde haya habido fallo y donde no en un espacio mediante el empleo de vectores clasificadores. Es decir, volveremos a emplear como variable 'y' la variable de **Machine Failure**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2996bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machines():\n",
    "    dataset = pd.read_csv(\"../../data/ai4i2020.csv\")\n",
    "\n",
    "    # Como X cogemos todas las columnas menos la variable que usaremos como 'y' y la variable de identificador\n",
    "    X, y = dataset.drop(columns=[\"UDI\", \"Machine failure\"]), dataset[\"Machine failure\"] \n",
    "\n",
    "    # Pasamos a númericas las variables categóricas\n",
    "    columnas_categoricas = X.select_dtypes(include=[\"object\"]).columns\n",
    "    X = pd.get_dummies(X, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "    # Dividimos el dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "    model_svm = svm.SVC()\n",
    "    model_svm.fit(X_train, y_train)\n",
    "\n",
    "    # Realizamos las predicciones\n",
    "    preds = model_svm.predict(X_test)\n",
    "\n",
    "    # Por ahora solo tendremos como métrica de evaluación la accuracy\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    print(f\"Accuracy obtenida: {accuracy:.4f}\")\n",
    "\n",
    "    # A partir de ahora, configuraremos el modelo para que sea compatible con BentoML\n",
    "    bento_svm = bentoml.sklearn.save_model(\n",
    "        \"ai4i2020_suppor_vector_machine\",\n",
    "        model_svm,\n",
    "        metadata={\n",
    "            \"fecha_entrenamiento\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"dataset\": \"ai4i2020\",\n",
    "            \"framework\": \"scikit-learn\",\n",
    "            \"algoritmo\": \"clasificación con svms\",\n",
    "            \"precision\": accuracy,\n",
    "            \"carta_favorita_cr\": \"Reina Arquera MOMO SHOW\"\n",
    "        },\n",
    "    )\n",
    "    print(f\"Modelo de Clasificación con Support Vector Machines (SVMs) guardado en la BentoML store como: {bento_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c02ab8",
   "metadata": {},
   "source": [
    "Ejecutémoslo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "727ca411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtenida: 0.9695\n",
      "Modelo de Clasificación con Support Vector Machines (SVMs) guardado en la BentoML store como: Model(tag=\"ai4i2020_suppor_vector_machine:y3io4dgpjsumt7fk\")\n"
     ]
    }
   ],
   "source": [
    "support_vector_machines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be723cf",
   "metadata": {},
   "source": [
    "## Para alistar los modelos creados en la BentoML Store:\n",
    "Al ejecutar el siguiente comando, podremos ver datos sobre el modelo como su nombre (con su tag), el módulo usado, el tamaño final del modelo y la fecha de creación del modelo. Cada vez que ejecutemos una función que llame al entrenamiento de un algoritmo, se creará otro con un tag distinto. Pudiendo haber más de una instancia por algoritmo, el tag los diferenciará. En el caso de que queramos eliminar una instancia, tendremos que usar el siguiente comando:\n",
    "\n",
    "```bash\n",
    "bendoml models delete <nombre del modelo (con su tag)>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "593d48e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/unai/miniconda3/envs/coran-nlp/lib/python3.11/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n",
      "\u001b[1m \u001b[0m\u001b[1mTag                         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n",
      " ai4i2020_suppor_vector_mach…  bentoml.sklearn  43.36 MiB   2025-12-02 08:01:50 \n",
      " ai4i2020_random_forest:rzbs…  bentoml.sklearn  22.91 MiB   2025-12-02 08:00:15 \n",
      " ai4i2020_logistic_regressio…  bentoml.sklearn  275.34 KiB  2025-12-02 07:59:28 \n",
      " make_classification_logisti…  bentoml.sklearn  1.35 KiB    2025-11-28 19:59:51 \n",
      " flower_model_iris:mrlpxugmq…  bentoml.sklearn  182.98 KiB  2025-11-28 19:23:52 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coran-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
