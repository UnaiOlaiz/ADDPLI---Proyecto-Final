{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94113ac",
   "metadata": {},
   "source": [
    "# Notebook de Creación del Servicio de API para Despliegue en BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83565122",
   "metadata": {},
   "source": [
    "# 1. Importación de librerías necesarias\n",
    "Este bloque importa todo lo que necesitaremos para cargar el modelo, el scaler y construir el servicio BentoML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38641878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import numpy as np\n",
    "from bentoml.io import NumpyNdarray\n",
    "from bentoml import Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1139eb",
   "metadata": {},
   "source": [
    "# 2. Cargar el modelo entrenado desde el Model Store\n",
    "\n",
    "En esta sección indicamos qué modelo queremos desplegar.\n",
    "Lo obtenemos desde el Model Store de BentoML mediante su tag y lo convertimos en un runner, que es la interfaz que BentoML usa para ejecutar el modelo de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3e2b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí va el modelo entrenado que queremos servir\n",
    "XGB_TAG   = \"ai4i2020_xgbclassifier:latest\"\n",
    "LOGR_TAG  = \"ai4i2020_logistic_regression:latest\"\n",
    "SVM_TAG   = \"ai4i2020_support_vector_machine:latest\"\n",
    "RF_TAG    = \"ai4i2020_random_forest:latest\"\n",
    "HDBSCAN_TAG = \"ai4i2020_hdbscan:latest\"\n",
    "\n",
    "# Cargar el modelo sklearn como un runner de BentoML\n",
    "xgb_runner  = bentoml.sklearn.get(XGB_TAG).to_runner()\n",
    "logr_runner = bentoml.sklearn.get(LOGR_TAG).to_runner()\n",
    "svm_runner  = bentoml.sklearn.get(SVM_TAG).to_runner()\n",
    "rf_runner   = bentoml.sklearn.get(RF_TAG).to_runner()\n",
    "hdbscan_runner = bentoml.sklearn.get(HDBSCAN_TAG).to_runner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddad255",
   "metadata": {},
   "source": [
    "# 3. Definir un Runner personalizado para el scaler\n",
    "\n",
    "Los scalers los guardamos como picklable_model, por lo que BentoML no conoce automáticamente sus métodos.\n",
    "Necesitamos crear una clase Runnable que exponga el método .transform() de StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "37a7a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag del scaler dentro del Model Store\n",
    "XGB_SCALER_TAG  = \"ai4i2020_scaler_xgbclassifier:latest\"\n",
    "LOGR_SCALER_TAG = \"ai4i2020_scaler_logistic_regression:latest\"\n",
    "SVM_SCALER_TAG  = \"ai4i2020_scaler_svm:latest\"\n",
    "RF_SCALER_TAG   = \"ai4i2020_scaler_random_forest:latest\"\n",
    "HDBSCAN_TAG     = \"ai4i2020_scaler_hdbscan:latest\"\n",
    "\n",
    "class XGBScalerRunnable(Runnable):\n",
    "    # obligatorio para BentoML runner/strategy\n",
    "    SUPPORTED_RESOURCES = (\"cpu\",)\n",
    "    # indicar capacidades de concurrencia que BentoML consulta\n",
    "    SUPPORTS_CPU_MULTI_THREADING = True\n",
    "\n",
    "    def __init__(self):\n",
    "        print(f\"Cargando el scaler desde el Model Store {XGB_SCALER_TAG}...\")\n",
    "        self.scaler = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n",
    "        print(\"¡Scaler cargado!\")\n",
    "\n",
    "    # @bentoml.runnable.method define una función que el runner puede llamar\n",
    "    @Runnable.method(batchable=True, batch_dim=0)\n",
    "    def transform(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return self.scaler.transform(input_data)\n",
    "    \n",
    "class LogrScalerRunnable(Runnable):\n",
    "    # obligatorio para BentoML runner/strategy\n",
    "    SUPPORTED_RESOURCES = (\"cpu\",)\n",
    "    # indicar capacidades de concurrencia que BentoML consulta\n",
    "    SUPPORTS_CPU_MULTI_THREADING = True\n",
    "\n",
    "    def __init__(self):\n",
    "        print(f\"Cargando el scaler desde el Model Store {LOGR_SCALER_TAG}...\")\n",
    "        self.scaler = bentoml.picklable_model.load_model(LOGR_SCALER_TAG)\n",
    "        print(\"¡Scaler cargado!\")\n",
    "\n",
    "    # @bentoml.runnable.method define una función que el runner puede llamar\n",
    "    @Runnable.method(batchable=True, batch_dim=0)\n",
    "    def transform(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return self.scaler.transform(input_data)\n",
    "    \n",
    "class SVMScalerRunnable(Runnable):\n",
    "    # obligatorio para BentoML runner/strategy\n",
    "    SUPPORTED_RESOURCES = (\"cpu\",)\n",
    "    # indicar capacidades de concurrencia que BentoML consulta\n",
    "    SUPPORTS_CPU_MULTI_THREADING = True\n",
    "\n",
    "    def __init__(self):\n",
    "        print(f\"Cargando el scaler desde el Model Store {SVM_SCALER_TAG}...\")\n",
    "        self.scaler = bentoml.picklable_model.load_model(SVM_SCALER_TAG)\n",
    "        print(\"¡Scaler cargado!\")\n",
    "\n",
    "    # @bentoml.runnable.method define una función que el runner puede llamar\n",
    "    @Runnable.method(batchable=True, batch_dim=0)\n",
    "    def transform(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return self.scaler.transform(input_data)\n",
    "    \n",
    "class RFScalerRunnable(Runnable):\n",
    "    # obligatorio para BentoML runner/strategy\n",
    "    SUPPORTED_RESOURCES = (\"cpu\",)\n",
    "    # indicar capacidades de concurrencia que BentoML consulta\n",
    "    SUPPORTS_CPU_MULTI_THREADING = True\n",
    "\n",
    "    def __init__(self):\n",
    "        print(f\"Cargando el scaler desde el Model Store {RF_SCALER_TAG}...\")\n",
    "        self.scaler = bentoml.picklable_model.load_model(RF_SCALER_TAG)\n",
    "        print(\"¡Scaler cargado!\")\n",
    "\n",
    "    # @bentoml.runnable.method define una función que el runner puede llamar\n",
    "    @Runnable.method(batchable=True, batch_dim=0)\n",
    "    def transform(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return self.scaler.transform(input_data)\n",
    "    \n",
    "class HDBSCANScalerRunnable(Runnable):\n",
    "    # obligatorio para BentoML runner/strategy\n",
    "    SUPPORTED_RESOURCES = (\"cpu\",)\n",
    "    # indicar capacidades de concurrencia que BentoML consulta\n",
    "    SUPPORTS_CPU_MULTI_THREADING = True\n",
    "\n",
    "    def __init__(self):\n",
    "        print(f\"Cargando el scaler desde el Model Store {HDBSCAN_TAG}...\")\n",
    "        self.scaler = bentoml.picklable_model.load_model(HDBSCAN_TAG)\n",
    "        print(\"¡Scaler cargado!\")\n",
    "\n",
    "    # @bentoml.runnable.method define una función que el runner puede llamar\n",
    "    @Runnable.method(batchable=True, batch_dim=0)\n",
    "    def transform(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        return self.scaler.transform(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cabe6",
   "metadata": {},
   "source": [
    "# 4. Instanciar el Runner del scaler\n",
    "\n",
    "Aquí convertimos la clase ScalerRunnable en un Runner que BentoML puede ejecutar de manera eficiente y asíncrona, igual que hace con los modelos sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cc4c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19068\\3403596579.py:2: BentoMLDeprecationWarning: `Runner` is deprecated since BentoML v1.4 and will be removed in a future version. Please upgrade to new style services.\n",
      "  xgb_scaler_runner  = bentoml.Runner(XGBScalerRunnable)\n",
      "Using lowercased runnable class name 'xgbscalerrunnable' for runner.\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19068\\3403596579.py:3: BentoMLDeprecationWarning: `Runner` is deprecated since BentoML v1.4 and will be removed in a future version. Please upgrade to new style services.\n",
      "  logr_scaler_runner = bentoml.Runner(LogrScalerRunnable)\n",
      "Using lowercased runnable class name 'logrscalerrunnable' for runner.\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19068\\3403596579.py:4: BentoMLDeprecationWarning: `Runner` is deprecated since BentoML v1.4 and will be removed in a future version. Please upgrade to new style services.\n",
      "  svm_scaler_runner  = bentoml.Runner(SVMScalerRunnable)\n",
      "Using lowercased runnable class name 'svmscalerrunnable' for runner.\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19068\\3403596579.py:5: BentoMLDeprecationWarning: `Runner` is deprecated since BentoML v1.4 and will be removed in a future version. Please upgrade to new style services.\n",
      "  rf_scaler_runner   = bentoml.Runner(RFScalerRunnable)\n",
      "Using lowercased runnable class name 'rfscalerrunnable' for runner.\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19068\\3403596579.py:6: BentoMLDeprecationWarning: `Runner` is deprecated since BentoML v1.4 and will be removed in a future version. Please upgrade to new style services.\n",
      "  hdbscan_scaler_runner = bentoml.Runner(HDBSCANScalerRunnable)\n",
      "Using lowercased runnable class name 'hdbscanscalerrunnable' for runner.\n"
     ]
    }
   ],
   "source": [
    "# 3. Crear el scaler_runner a partir de nuestra CLASE personalizada\n",
    "xgb_scaler_runner  = bentoml.Runner(XGBScalerRunnable)\n",
    "logr_scaler_runner = bentoml.Runner(LogrScalerRunnable)\n",
    "svm_scaler_runner  = bentoml.Runner(SVMScalerRunnable)\n",
    "rf_scaler_runner   = bentoml.Runner(RFScalerRunnable)\n",
    "hdbscan_scaler_runner = bentoml.Runner(HDBSCANScalerRunnable)\n",
    "runners = [\n",
    "    xgb_runner, logr_runner, svm_runner, rf_runner, hdbscan_runner,\n",
    "    xgb_scaler_runner, logr_scaler_runner, svm_scaler_runner, rf_scaler_runner, hdbscan_scaler_runner\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c5428",
   "metadata": {},
   "source": [
    "# 5. Crear el servicio BentoML con ambos runners\n",
    "\n",
    "Un Service es el servidor que expondrá los endpoints.\n",
    "Aquí registramos los dos runners:\n",
    "\n",
    "- El del modelo (predicción)\n",
    "- El del scaler (preprocesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21c3d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_19068\\1532436793.py:2: BentoMLDeprecationWarning: `bentoml.Service` is deprecated since BentoML v1.4 and will be removed in a future version. Please upgrade to @bentoml.service().\n",
      "  svc = bentoml.Service(\n",
      "Converting AI4I2020__Failure__Prediction__Service to lowercase: ai4i2020__failure__prediction__service.\n"
     ]
    }
   ],
   "source": [
    "# Crear el servicio que incluirá el runner del modelo y el runner del scaler\n",
    "svc = bentoml.Service(\n",
    "    \"AI4I2020__Failure__Prediction__Service\",\n",
    "    runners=runners,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613d9e8",
   "metadata": {},
   "source": [
    "# 6. Definir el endpoint HTTP\n",
    "\n",
    "Este endpoint recibe un array NumPy, lo escala y lo pasa al modelo para obtener predicciones. sample_array_input define la forma de la entrada que BentoML usará para validar y generar la documentación de la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f36086c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_12 = 12\n",
    "FEATURES_7  = 7\n",
    "\n",
    "sample_12 = [[0.0] * FEATURES_12]\n",
    "sample_7  = [[0.0] * FEATURES_7]\n",
    "\n",
    "@svc.api(input=NumpyNdarray.from_sample(sample_12), output=NumpyNdarray())\n",
    "async def predict_logreg(input_data: np.ndarray) -> np.ndarray:\n",
    "    scaled = await logr_scaler_runner.transform.async_run(input_data)\n",
    "    probs  = await logr_runner.predict_proba.async_run(scaled)\n",
    "    return probs\n",
    "\n",
    "@svc.api(input=NumpyNdarray.from_sample(sample_7), output=NumpyNdarray())\n",
    "async def predict_random_forest(input_data: np.ndarray) -> np.ndarray:\n",
    "    scaled = await rf_scaler_runner.transform.async_run(input_data)\n",
    "    preds  = await rf_runner.predict.async_run(scaled)   # multioutput (5 columnas)\n",
    "    return preds\n",
    "\n",
    "@svc.api(input=NumpyNdarray.from_sample(sample_12), output=NumpyNdarray())\n",
    "async def predict_svm(input_data: np.ndarray) -> np.ndarray:\n",
    "    scaled = await svm_scaler_runner.transform.async_run(input_data)\n",
    "    probs  = await svm_runner.predict_proba.async_run(scaled)\n",
    "    return probs\n",
    "\n",
    "@svc.api(input=NumpyNdarray.from_sample(sample_12), output=NumpyNdarray())\n",
    "async def predict_xgb(input_data: np.ndarray) -> np.ndarray:\n",
    "    scaled = await xgb_scaler_runner.transform.async_run(input_data)\n",
    "    preds  = await xgb_runner.predict.async_run(scaled)\n",
    "    return preds\n",
    "\n",
    "@svc.api(input=NumpyNdarray.from_sample(sample_7), output=NumpyNdarray())\n",
    "async def cluster_hdbscan(input_data: np.ndarray) -> np.ndarray:\n",
    "    scaled = await hdbscan_scaler_runner.transform.async_run(input_data)\n",
    "    labels = await hdbscan_runner.predict.async_run(scaled)  # o fit_predict según lo que guardaste\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a639b47",
   "metadata": {},
   "source": [
    "http://localhost:3000/\n",
    "\n",
    "body para xgb:\n",
    "[\n",
    "    [298.1, 308.6, 1551, 42.8, 0,\n",
    "     0, 0, 0, 0, 0,\n",
    "     0, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!cd C:/Users/diego/Carrera/4º/Analítica/ADDPLI---Proyecto-Final/src/BentoML && bentoml serve service:svc --port 3000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analitica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
