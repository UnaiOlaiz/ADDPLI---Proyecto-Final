{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94113ac",
   "metadata": {},
   "source": [
    "# Notebook de Creación del Servicio de API para Despliegue en BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac93ce3",
   "metadata": {},
   "source": [
    "Mediante este notebook pretendemos crear el servicio API para deplegar BentoML y los modelos que hemos creado. Como mención aclarativa, el procedimiento que hemos seguido es fundamentalmente igual que el código proporcionado en clase para realizar las practicas de BentoML. Sin embargo, por motivos de dependecias y obsolescencias (las nuevas versiones pedian metodos más modernos), hemos decidio usar una solución más moderna y adaptada a nuestros intereses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83565122",
   "metadata": {},
   "source": [
    "## 1. Importación de librerías necesarias\n",
    "Aquí simplemente traemos las librerías que necesitamos: BentoML para crear el servicio, NumPy para manejar los números y Pydantic para definir cómo son los datos que vamos a recibir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38641878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1139eb",
   "metadata": {},
   "source": [
    "## 2. Cargar el modelo entrenado desde el Model Store\n",
    "\n",
    "En este bloque, definimos los \"nombres clave\" (Tags) con los que guardamos nuestros modelos y escaladores anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e2b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_TAG            = \"ai4i2020_xgbclassifier:latest\"\n",
    "LOGR_TAG           = \"ai4i2020_logistic_regression:latest\"\n",
    "SVM_TAG            = \"ai4i2020_support_vector_machine:latest\"\n",
    "RF_TAG             = \"ai4i2020_random_forest:latest\"\n",
    "HDBSCAN_MODEL_TAG  = \"ai4i2020_hdbscan:latest\"\n",
    "\n",
    "XGB_SCALER_TAG       = \"ai4i2020_scaler_xgbclassifier:latest\"\n",
    "LOGR_SCALER_TAG      = \"ai4i2020_scaler_logistic_regression:latest\"\n",
    "SVM_SCALER_TAG       = \"ai4i2020_scaler_svm:latest\"\n",
    "RF_SCALER_TAG        = \"ai4i2020_scaler_random_forest:latest\"\n",
    "HDBSCAN_SCALER_TAG   = \"ai4i2020_scaler_hdbscan:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddad255",
   "metadata": {},
   "source": [
    "## 3. Definir los Schemas de entrada\n",
    "\n",
    "Aquí creamos dos moldes para los datos. Además, ponemos un ejemplo por defecto para que aparezca bonito en la página web del servicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esquema para modelos de 12 columnas (Logistic, SVM, XGB)\n",
    "class Input7Features2(BaseModel):\n",
    "    # Definimos que esperamos una lista de listas de floats\n",
    "    input_data: list[list[float]] = Field(\n",
    "        default=[[298.9, 309.1, 2861, 4.6, 143, 1, 0]],\n",
    "        description=\"Matriz de entrada con 12 características.\"\n",
    "    )\n",
    "\n",
    "# Esquema para modelos de 7 columnas (Random Forest, HDBSCAN) (los modelos que obvian el tipo de fallo; ya que serán parte de 'y' o serán obviados)\n",
    "class Input7Features(BaseModel):\n",
    "    input_data: list[list[float]] = Field(\n",
    "        default=[[298.8, 308.9, 1455, 41.3, 208, 1, 0]],\n",
    "        description=\"Matriz de entrada con 7 características.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cabe6",
   "metadata": {},
   "source": [
    "## 4. Cargamos los modelos en la memoria\n",
    "Este es el momento en que el servidor arranca. Usamos las etiquetas que definimos antes para sacar los modelos reales del disco y cargarlos en la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc4c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando MODELOS del Model Store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unai-olaizola-osa/miniconda3/envs/ADDPLD/lib/python3.13/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando SCALERS del Model Store...\n",
      "Modelos y scalers cargados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13619/2873539173.py:9: BentoMLDeprecationWarning: `bentoml.picklable_model` is deprecated since v1.4 and will be removed in a future version.\n",
      "  xgb_scaler   = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando MODELOS del Model Store...\")\n",
    "xgb_model   = bentoml.sklearn.load_model(XGB_TAG)\n",
    "logr_model  = bentoml.sklearn.load_model(LOGR_TAG)\n",
    "svm_model   = bentoml.sklearn.load_model(SVM_TAG)\n",
    "rf_model    = bentoml.sklearn.load_model(RF_TAG)\n",
    "hdb_model   = bentoml.sklearn.load_model(HDBSCAN_MODEL_TAG)\n",
    "\n",
    "print(\"Cargando SCALERS del Model Store...\")\n",
    "xgb_scaler   = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n",
    "logr_scaler  = bentoml.picklable_model.load_model(LOGR_SCALER_TAG)\n",
    "svm_scaler   = bentoml.picklable_model.load_model(SVM_SCALER_TAG)\n",
    "rf_scaler    = bentoml.picklable_model.load_model(RF_SCALER_TAG)\n",
    "hdb_scaler   = bentoml.picklable_model.load_model(HDBSCAN_SCALER_TAG)\n",
    "\n",
    "print(\"Modelos y scalers cargados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c5428",
   "metadata": {},
   "source": [
    "## 5. Configuramos el servicio y nuestro asistente de limpieza\n",
    "Aquí empieza la clase principal. Primero, creamos una función \"ayudante\" (_prepare_data) que usamos internamente. Esta función se encarga de recibir los datos brutos, convertirlos al formato NumPy y comprobar que el tamaño sea el correcto antes de pasárselos a los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c3d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bentoml.service(name=\"AI4I2020__Failure__Prediction__Service\")\n",
    "class AI4I2020FailurePredictionService:\n",
    "    \"\"\"\n",
    "    Servicio BentoML con Inputs definidos mediante Pydantic\n",
    "    para mostrar ejemplos en la UI (Swagger).\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir pydantic a numpy y validar\n",
    "    def _prepare_data(self, pydantic_input, expected_cols: int) -> np.ndarray:\n",
    "        # Extraemos la lista del objeto pydantic y convertimos a numpy\n",
    "        data = np.array(pydantic_input.input_data)\n",
    "        \n",
    "        # Aseguramos 2D\n",
    "        if data.ndim == 1:\n",
    "            data = data.reshape(1, -1)\n",
    "            \n",
    "        # Validamos columnas\n",
    "        if data.shape[1] != expected_cols:\n",
    "            raise ValueError(f\"Se esperaban {expected_cols} columnas, recibidas {data.shape[1]}.\")\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613d9e8",
   "metadata": {},
   "source": [
    "## 6. Creamos las \"ventanillas\" de atención (Endpoints)\n",
    "Finalmente, definimos las funciones que estarán disponibles para el público. Cada función hace lo mismo:\n",
    "1. Recibe los datos del usuario.\n",
    "2. Llama al ayudante (_prepare_data) para limpiarlos.\n",
    "3. Escala los datos.\n",
    "4. Le pide al modelo correspondiente una predicción y nos la devuelve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36086c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (Usa Input7Features2)\n",
    "@bentoml.api\n",
    "def predict_logreg(self, input_obj: Input7Features2) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = logr_scaler.transform(data)\n",
    "    return logr_model.predict_proba(scaled)\n",
    "\n",
    "# Random Forest (Usa Input7Features)\n",
    "@bentoml.api\n",
    "def predict_random_forest(self, input_obj: Input7Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = rf_scaler.transform(data)\n",
    "    return rf_model.predict(scaled)\n",
    "\n",
    "# SVM (Usa Input7Features2)\n",
    "@bentoml.api\n",
    "def predict_svm(self, input_obj: Input7Features2) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = svm_scaler.transform(data)\n",
    "    return svm_model.predict_proba(scaled)\n",
    "\n",
    "# XGBoost (Usa Input7Features2)\n",
    "@bentoml.api\n",
    "def predict_xgb(self, input_obj: Input7Features2) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = xgb_scaler.transform(data)\n",
    "    return xgb_model.predict(scaled)\n",
    "\n",
    "# HDBSCAN (Usa Input7Features)\n",
    "@bentoml.api\n",
    "def cluster_hdbscan(self, input_obj: Input7Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = hdb_scaler.transform(data)\n",
    "    # Recordamos que aquí estamos usando el truco del KNN wrapper\n",
    "    # por lo que podemos usar .predict() directamente\n",
    "    predictions = hdb_model.predict(scaled)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53dc2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/unai-olaizola-osa/miniconda3/envs/ADDPLD/lib/python3.13/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n",
      "Cargando MODELOS del Model Store...\n",
      "Cargando SCALERS del Model Store...\n",
      "/home/unai-olaizola-osa/Documents/4/ADDPLI/ADDPLI---Proyecto-Final/src/BentoML/service.py:41: BentoMLDeprecationWarning: `bentoml.picklable_model` is deprecated since v1.4 and will be removed in a future version.\n",
      "  xgb_scaler   = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n",
      "Modelos y scalers cargados.\n",
      "2025-12-12T20:36:35+0100 [INFO] [cli] Starting production HTTP BentoServer from \"service:AI4I2020FailurePredictionService\" listening on http://localhost:3000 (Press CTRL+C to quit)\n",
      "/home/unai-olaizola-osa/miniconda3/envs/ADDPLD/lib/python3.13/site-packages/fs/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n",
      "Cargando MODELOS del Model Store...\n",
      "Cargando SCALERS del Model Store...\n",
      "/home/unai-olaizola-osa/Documents/4/ADDPLI/ADDPLI---Proyecto-Final/src/BentoML/service.py:41: BentoMLDeprecationWarning: `bentoml.picklable_model` is deprecated since v1.4 and will be removed in a future version.\n",
      "  xgb_scaler   = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n",
      "Modelos y scalers cargados.\n",
      "2025-12-12T20:36:37+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] Service AI4I2020__Failure__Prediction__Service initialized\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46392 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2945) 7.103ms (trace=1d373448f08a754bbe47ccd05f54c8a1,span=17e65067112d54a4,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46392 (scheme=http,method=GET,path=/static_content/swagger-ui.css,type=,length=) (status=304,type=,length=) 8.952ms (trace=910c25c49203ca0468140d295f17dcf4,span=2ca48aec03553744,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46402 (scheme=http,method=GET,path=/static_content/swagger-ui-standalone-preset.js,type=,length=) (status=304,type=,length=) 7.512ms (trace=bb2c2824a24b7b55aacff0777713fd1f,span=8bcd15ebaebec213,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46396 (scheme=http,method=GET,path=/static_content/index.css,type=,length=) (status=304,type=,length=) 10.988ms (trace=7e9118ac3d9685bec9f22717d421d8a6,span=61b929958a88ecb5,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46398 (scheme=http,method=GET,path=/static_content/swagger-ui-bundle.js,type=,length=) (status=304,type=,length=) 11.809ms (trace=37ce92692f18a757c46c7ef1c8383c83,span=c69a881bb13a4d38,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46400 (scheme=http,method=GET,path=/static_content/swagger-initializer.js,type=,length=) (status=200,type=text/javascript; charset=utf-8,length=331) 12.307ms (trace=10b4a08c5aa9c5c7fd268dae14b03137,span=07df97e7fcd0ed85,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46400 (scheme=http,method=GET,path=/static_content/favicon-dark-32x32.png,type=,length=) (status=200,type=image/png,length=654) 1.149ms (trace=c4507d805d571b15b2d33732db12c3d0,span=13225a5446286640,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "2025-12-12T20:36:38+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:46402 (scheme=http,method=GET,path=/docs.json,type=,length=) (status=200,type=application/json,length=9769) 25.314ms (trace=9c459b09c04cfebaf3866142d28d5a87,span=17dd306746940aea,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "/home/unai-olaizola-osa/miniconda3/envs/ADDPLD/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-12-12T20:37:08+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:33708 (scheme=http,method=POST,path=/cluster_hdbscan,type=application/json,length=71) (status=200,type=application/json,length=3) 10.475ms (trace=1d0e9d1fa340573b12437d0f6f18aab1,span=b7c6620db6da0fd6,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "/home/unai-olaizola-osa/miniconda3/envs/ADDPLD/lib/python3.13/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-12-12T20:37:43+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] 127.0.0.1:36956 (scheme=http,method=POST,path=/predict_xgb,type=application/json,length=85) (status=200,type=application/json,length=3) 9.051ms (trace=bc5ccf6207cbef2f2255dad803689984,span=a82799035700e27d,sampled=0,service.name=AI4I2020__Failure__Prediction__Service)\n",
      "^C\n",
      "2025-12-12T20:38:15+0100 [INFO] [entry_service:AI4I2020__Failure__Prediction__Service:1] Service instance cleanup finalized\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service:AI4I2020FailurePredictionService --port 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c080b4",
   "metadata": {},
   "source": [
    "http://localhost:3000/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analitica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
