{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94113ac",
   "metadata": {},
   "source": [
    "# Notebook de Creación del Servicio de API para Despliegue en BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83565122",
   "metadata": {},
   "source": [
    "# 1. Importación de librerías necesarias\n",
    "Aquí simplemente traemos las librerías que necesitamos: BentoML para crear el servicio, NumPy para manejar los números y Pydantic para definir cómo son los datos que vamos a recibir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38641878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1139eb",
   "metadata": {},
   "source": [
    "# 2. Cargar el modelo entrenado desde el Model Store\n",
    "\n",
    "En este bloque, definimos los \"nombres clave\" (Tags) con los que guardamos nuestros modelos y escaladores anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e2b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_TAG            = \"ai4i2020_xgbclassifier:latest\"\n",
    "LOGR_TAG           = \"ai4i2020_logistic_regression:latest\"\n",
    "SVM_TAG            = \"ai4i2020_support_vector_machine:latest\"\n",
    "RF_TAG             = \"ai4i2020_random_forest:latest\"\n",
    "HDBSCAN_MODEL_TAG  = \"ai4i2020_hdbscan:latest\"\n",
    "\n",
    "XGB_SCALER_TAG       = \"ai4i2020_scaler_xgbclassifier:latest\"\n",
    "LOGR_SCALER_TAG      = \"ai4i2020_scaler_logistic_regression:latest\"\n",
    "SVM_SCALER_TAG       = \"ai4i2020_scaler_svm:latest\"\n",
    "RF_SCALER_TAG        = \"ai4i2020_scaler_random_forest:latest\"\n",
    "HDBSCAN_SCALER_TAG   = \"ai4i2020_scaler_hdbscan:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddad255",
   "metadata": {},
   "source": [
    "# 3. Definir los Schemas de entrada\n",
    "\n",
    "Aquí creamos dos moldes para los datos. Además, ponemos un ejemplo por defecto para que aparezca bonito en la página web del servicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a7a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esquema para modelos de 12 columnas (Logistic, SVM, XGB)\n",
    "class Input12Features(BaseModel):\n",
    "    # Definimos que esperamos una lista de listas de floats\n",
    "    input_data: list[list[float]] = Field(\n",
    "        default=[[298.9, 309.1, 2861, 4.6, 143, 0, 0, 1, 0, 0, 1, 0]],\n",
    "        description=\"Matriz de entrada con 12 características.\"\n",
    "    )\n",
    "\n",
    "# Esquema para modelos de 7 columnas (Random Forest, HDBSCAN)\n",
    "class Input7Features(BaseModel):\n",
    "    input_data: list[list[float]] = Field(\n",
    "        default=[[298.8, 308.9, 1455, 41.3, 208, 1, 0]],\n",
    "        description=\"Matriz de entrada con 7 características.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cabe6",
   "metadata": {},
   "source": [
    "# 4. Cargamos los modelos en la memoria\n",
    "Este es el momento en que el servidor arranca. Usamos las etiquetas que definimos antes para sacar los modelos reales del disco y cargarlos en la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc4c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando MODELOS del Model Store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\Carrera\\4º\\Analítica\\ADDPLI---Proyecto-Final\\analitica\\Lib\\site-packages\\fs\\__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando SCALERS del Model Store...\n",
      "Modelos y scalers cargados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_1440\\2873539173.py:9: BentoMLDeprecationWarning: `bentoml.picklable_model` is deprecated since v1.4 and will be removed in a future version.\n",
      "  xgb_scaler   = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando MODELOS del Model Store...\")\n",
    "xgb_model   = bentoml.sklearn.load_model(XGB_TAG)\n",
    "logr_model  = bentoml.sklearn.load_model(LOGR_TAG)\n",
    "svm_model   = bentoml.sklearn.load_model(SVM_TAG)\n",
    "rf_model    = bentoml.sklearn.load_model(RF_TAG)\n",
    "hdb_model   = bentoml.sklearn.load_model(HDBSCAN_MODEL_TAG)\n",
    "\n",
    "print(\"Cargando SCALERS del Model Store...\")\n",
    "xgb_scaler   = bentoml.picklable_model.load_model(XGB_SCALER_TAG)\n",
    "logr_scaler  = bentoml.picklable_model.load_model(LOGR_SCALER_TAG)\n",
    "svm_scaler   = bentoml.picklable_model.load_model(SVM_SCALER_TAG)\n",
    "rf_scaler    = bentoml.picklable_model.load_model(RF_SCALER_TAG)\n",
    "hdb_scaler   = bentoml.picklable_model.load_model(HDBSCAN_SCALER_TAG)\n",
    "\n",
    "print(\"Modelos y scalers cargados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c5428",
   "metadata": {},
   "source": [
    "# 5. Configuramos el servicio y nuestro asistente de limpieza\n",
    "Aquí empieza la clase principal. Primero, creamos una función \"ayudante\" (_prepare_data) que usamos internamente. Esta función se encarga de recibir los datos brutos, convertirlos al formato NumPy y comprobar que el tamaño sea el correcto antes de pasárselos a los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c3d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bentoml.service(name=\"AI4I2020__Failure__Prediction__Service\")\n",
    "class AI4I2020FailurePredictionService:\n",
    "    \"\"\"\n",
    "    Servicio BentoML con Inputs definidos mediante Pydantic\n",
    "    para mostrar ejemplos en la UI (Swagger).\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir pydantic a numpy y validar\n",
    "    def _prepare_data(self, pydantic_input, expected_cols: int) -> np.ndarray:\n",
    "        # Extraemos la lista del objeto pydantic y convertimos a numpy\n",
    "        data = np.array(pydantic_input.input_data)\n",
    "        \n",
    "        # Aseguramos 2D\n",
    "        if data.ndim == 1:\n",
    "            data = data.reshape(1, -1)\n",
    "            \n",
    "        # Validamos columnas\n",
    "        if data.shape[1] != expected_cols:\n",
    "            raise ValueError(f\"Se esperaban {expected_cols} columnas, recibidas {data.shape[1]}.\")\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613d9e8",
   "metadata": {},
   "source": [
    "# 6. Creamos las \"ventanillas\" de atención (Endpoints)\n",
    "Finalmente, definimos las funciones que estarán disponibles para el público. Cada función hace lo mismo:\n",
    "1. Recibe los datos del usuario.\n",
    "2. Llama al ayudante (_prepare_data) para limpiarlos.\n",
    "3. Escala los datos.\n",
    "4. Le pide al modelo correspondiente una predicción y nos la devuelve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36086c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (Usa Input12Features)\n",
    "@bentoml.api\n",
    "def predict_logreg(self, input_obj: Input12Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 12)\n",
    "    scaled = logr_scaler.transform(data)\n",
    "    return logr_model.predict_proba(scaled)\n",
    "\n",
    "# Random Forest (Usa Input7Features)\n",
    "@bentoml.api\n",
    "def predict_random_forest(self, input_obj: Input7Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = rf_scaler.transform(data)\n",
    "    return rf_model.predict(scaled)\n",
    "\n",
    "# SVM (Usa Input12Features)\n",
    "@bentoml.api\n",
    "def predict_svm(self, input_obj: Input12Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 12)\n",
    "    scaled = svm_scaler.transform(data)\n",
    "    return svm_model.predict_proba(scaled)\n",
    "\n",
    "# XGBoost (Usa Input12Features)\n",
    "@bentoml.api\n",
    "def predict_xgb(self, input_obj: Input12Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 12)\n",
    "    scaled = xgb_scaler.transform(data)\n",
    "    return xgb_model.predict(scaled)\n",
    "\n",
    "# HDBSCAN (Usa Input7Features)\n",
    "@bentoml.api\n",
    "def cluster_hdbscan(self, input_obj: Input7Features) -> np.ndarray:\n",
    "    data = self._prepare_data(input_obj, 7)\n",
    "    scaled = hdb_scaler.transform(data)\n",
    "    # Recordamos que aquí estamos usando el truco del KNN wrapper\n",
    "    # por lo que podemos usar .predict() directamente\n",
    "    predictions = hdb_model.predict(scaled)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53dc2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service:AI4I2020FailurePredictionService --port 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c080b4",
   "metadata": {},
   "source": [
    "http://localhost:3000/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analitica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
